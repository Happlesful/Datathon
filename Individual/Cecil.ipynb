{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "#%pip install pyarrow\n",
    "#%pip install fastparquet\n",
    "#%pip install seaborn\n",
    "#%pip install scikit-learn\n",
    "\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parma\\OneDrive\\Documents\n",
      "          clntnum race_desc ctrycode_desc clttype stat_flag min_occ_date  \\\n",
      "19550  91b546e924   Chinese     Singapore       P    ACTIVE   2017-10-31   \n",
      "4600   896bae548c   Chinese     Singapore       P    ACTIVE   2007-05-23   \n",
      "13337  f364439ae6    Others     Singapore       P    ACTIVE   2019-08-31   \n",
      "15074  70f319cfe1   Chinese     Singapore       P    ACTIVE   2021-10-18   \n",
      "19724  2647a81328   Chinese     Singapore       P    ACTIVE   2018-07-20   \n",
      "\n",
      "       cltdob_fix cltsex_fix  flg_substandard  flg_is_borderline_standard  \\\n",
      "19550  1974-05-09     Female              0.0                         0.0   \n",
      "4600   1979-11-11       Male              0.0                         0.0   \n",
      "13337  1976-01-28       Male              0.0                         0.0   \n",
      "15074  1976-03-19     Female              0.0                         0.0   \n",
      "19724  1995-07-31     Female              0.0                         0.0   \n",
      "\n",
      "       ...  recency_giclaim  giclaim_cnt_success  recency_giclaim_success  \\\n",
      "19550  ...              NaN                 None                     None   \n",
      "4600   ...              NaN                 None                     None   \n",
      "13337  ...              NaN                 None                     None   \n",
      "15074  ...              NaN                 None                     None   \n",
      "19724  ...              NaN                 None                     None   \n",
      "\n",
      "       giclaim_cnt_unsuccess  recency_giclaim_unsuccess  \\\n",
      "19550                   None                       None   \n",
      "4600                    None                       None   \n",
      "13337                   None                       None   \n",
      "15074                   None                       None   \n",
      "19724                   None                       None   \n",
      "\n",
      "       flg_gi_claim_29d435_ever  flg_gi_claim_058815_ever  \\\n",
      "19550                      None                      None   \n",
      "4600                       None                      None   \n",
      "13337                      None                      None   \n",
      "15074                      None                      None   \n",
      "19724                      None                      None   \n",
      "\n",
      "       flg_gi_claim_42e115_ever  flg_gi_claim_856320_ever  f_purchase_lh  \n",
      "19550                      None                      None            NaN  \n",
      "4600                       None                      None            NaN  \n",
      "13337                      None                      None            NaN  \n",
      "15074                      None                      None            NaN  \n",
      "19724                      None                      None            NaN  \n",
      "\n",
      "[5 rows x 304 columns]\n"
     ]
    }
   ],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current working directory\n",
    "new_directory = \"C:/Users/parma/OneDrive/Documents\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "filepath = \"./data/catB_train.parquet\" \n",
    "\n",
    "data = pd.read_parquet(filepath)\n",
    "print(data.head())\n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###...code...###\n",
    "columnNames = [\"clntnum\", \"ctrycode_desc\", \"stat_flag\", \"min_occ_date\", \"cltdob_fix\", \"cltsex_fix\", \n",
    "               \"flg_substandard\", \"flg_is_borderline_standard\", \"flg_is_revised_term\", \"flg_has_health_claim\", \"flg_gi_claim\", \"flg_is_proposal\", \n",
    "               \"is_dependent_in_at_least_1_policy\", \"annual_income_est\", \"tot_inforce_pols\", \"tot_cancel_pols\", \"f_ever_declined_la\",\n",
    "               \"f_purchase_lh\"]\n",
    "data = data.loc[:, columnNames]\n",
    "\n",
    "# Adding cltage and clt_ten cols\n",
    "# Drop rows with incomplete data for `cltdob_fix`\n",
    "data['cltdob_fix'] = data['cltdob_fix'].replace(\"None\", pd.NaT)\n",
    "cltdob_rows = data[data['cltdob_fix'].isna()]\n",
    "data = data.dropna(subset=['cltdob_fix'])\n",
    "\n",
    "# Drop rows with incomplete data for `min_occ_date`\n",
    "data['min_occ_date'] = data['min_occ_date'].replace(\"None\", pd.NaT)\n",
    "occDate_rows = data[data['min_occ_date'].isna()]\n",
    "data = data.dropna(subset=['min_occ_date'])\n",
    "\n",
    "# Convert cltdob_fix to datetime format and compute the client's age\n",
    "currentDate = datetime.now()\n",
    "data[\"cltdob_fix\"] = data[\"cltdob_fix\"].map(\n",
    "    lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "data[\"cltage\"] = data[\"cltdob_fix\"].map(\n",
    "    lambda x: ((currentDate - x).days/365.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_income_est    float64\n",
      "tot_cancel_pols      float64\n",
      "dtype: object\n",
      "-0.02590562848189608\n",
      "0.009417747919448957\n",
      "0.05014613443800301\n"
     ]
    }
   ],
   "source": [
    "###Data Analysis\n",
    "\n",
    "##Filter the data for clients who are no longer active in SingLife\n",
    "df_inactive = data[data['stat_flag'] != 'ACTIVE']\n",
    "selected_colns = [\"flg_substandard\", \"flg_is_borderline_standard\", \"flg_is_revised_term\", \"is_dependent_in_at_least_1_policy\", \"annual_income_est\", \"tot_inforce_pols\", \"tot_cancel_pols\", \"f_ever_declined_la\",\n",
    "               \"f_purchase_lh\"]\n",
    "df_inactive = df_inactive.loc[:, selected_colns]\n",
    "\n",
    "##Checking total number of NAs for each column\n",
    "\n",
    "inforce_na = df_inactive['tot_inforce_pols'].isna().sum()\n",
    "cancelled_na = df_inactive['tot_cancel_pols'].isna().sum()\n",
    "declined_na = df_inactive[\"f_ever_declined_la\"].isna().sum()\n",
    "purchased_na = df_inactive[\"f_purchase_lh\"].isna().sum()\n",
    "\n",
    "#print(inforce_na), print(cancelled_na), print(declined_na), print(purchased_na)\n",
    "\n",
    "##Replace NA values with 0 in the selected columns\n",
    "colns_to_fill = [\"tot_inforce_pols\", \"tot_cancel_pols\", \"f_ever_declined_la\", \"f_purchase_lh\"]\n",
    "df_inactive[colns_to_fill] = df_inactive[colns_to_fill].fillna(0)\n",
    "\n",
    "income_mapping = {\n",
    "    'D.30K-60K': 45000,\n",
    "    'E.BELOW30K': 30000,\n",
    "    'A.ABOVE200K': 200000,\n",
    "    'C.60K-100K': 80000,\n",
    "    'B.100K-200K': 150000\n",
    "}\n",
    "\n",
    "df_inactive[\"annual_income_est\"] = df_inactive[\"annual_income_est\"].replace(income_mapping)\n",
    "\n",
    "colns_1 = [\"annual_income_est\", \"tot_cancel_pols\"]\n",
    "colns_2 = [\"annual_income_est\", 'f_ever_declined_la']\n",
    "colns_3 = [\"annual_income_est\", \"f_purchase_lh\"]\n",
    "df4 = df_inactive.loc[:,colns_1].dropna()\n",
    "df5 = df_inactive.loc[:, colns_2].dropna()\n",
    "df6 = df_inactive.loc[:,colns_3].dropna()\n",
    "\n",
    "#checking income and correlation with cancellation history\n",
    "print(df4.dtypes)\n",
    "r1 = df4[\"annual_income_est\"].corr(df4[\"tot_cancel_pols\"])\n",
    "print(r1)\n",
    "\n",
    "#checking income and correlation with purchase inclination\n",
    "r2 = df6[\"annual_income_est\"].corr(df6[\"f_purchase_lh\"])\n",
    "print(r2)\n",
    "\n",
    "#checking income and correlation with declined history\n",
    "r3 = df5[\"annual_income_est\"].corr(df5[\"f_ever_declined_la\"])\n",
    "print(r3)\n",
    "#print(df4[\"annual_income_est\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model: 0.9989001319841619\n"
     ]
    }
   ],
   "source": [
    "###Data modelling\n",
    "unique1 = data[\"flg_is_proposal\"].unique()\n",
    "unique2 = data[\"f_purchase_lh\"].unique()\n",
    "\n",
    "na1 = data[\"flg_is_proposal\"].isna().sum()\n",
    "na2 = data[\"f_purchase_lh\"].isna().sum()\n",
    "\n",
    "colns = [\"flg_is_proposal\", \"f_purchase_lh\"]\n",
    "data[colns]= data[colns].fillna(0) #those that have NA values become 0 instead\n",
    "\n",
    "data['conversion'] = np.where((data[\"flg_is_proposal\"] == 1) & (data[\"f_purchase_lh\"] == 1), True, False)\n",
    "\n",
    "#Convert income est from string to integers instead\n",
    "income_mapping = {\n",
    "    'D.30K-60K': 45000,\n",
    "    'E.BELOW30K': 30000,\n",
    "    'A.ABOVE200K': 200000,\n",
    "    'C.60K-100K': 80000,\n",
    "    'B.100K-200K': 150000\n",
    "}\n",
    "\n",
    "data[\"annual_income_est\"] = data[\"annual_income_est\"].replace(income_mapping)\n",
    "cleaned_df = data.dropna(subset=['annual_income_est', 'cltage'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "X = cleaned_df[[\"annual_income_est\", \"cltage\"]]\n",
    "Y = cleaned_df['conversion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Train the KNN model\n",
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_reg_model = LogisticRegression()\n",
    "logistic_reg_model.fit(X_train, y_train)\n",
    "y_pred = logistic_reg_model.predict(X_test)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of Logistic Regression model: {accuracy_logistic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
